stringsAsFactors=F)
colnames(lab9.df)
#
# 2. Create zoo object from data and dates in lab7.df
#
lab9.z = zoo(x=lab9.df[, -1],
order.by=as.yearmon(lab9.df[, 1], format="%b-%y"))
start(lab9.z)
end(lab9.z)
colnames(lab9.z)
#
# 3. Create timePlots of data
#
# create custom panel function to draw horizontal line at zero in each panel
# of plot
my.panel <- function(...) {
lines(...)
abline(h=0)
}
plot(lab9.z, lwd=2, panel=my.panel, col="blue")
# all on the same graph
plot(lab9.z, plot.type = "single", main="lab9 returns",
col=1:4, lwd=2)
abline(h=0)
legend(x="bottomleft", legend=colnames(lab7.z), col=1:4, lwd=2)
#
# 4. Compute pairwise scatterplots
#
# lab9.r		 lab9 calculations
#
# author: Eric Zivot
# created: November 1, 2008
# revised: August 11, 2011
#
# comments:
# Data for the lab are in the Excel file econ424lab7returns.csv, which contains monthly continuously
# compounded returns on Boeing, Nordstrom, Starbucks and Microsoft stocks over
# the period March, 1995 through January, 2000.
options(digits=4, width=70)
library("zoo")
# load the data into a zoo object using the zoo function read.csv
source(file="http://spark-public.s3.amazonaws.com/compfinance/R%20code/portfolio.r")
lab8.df = read.csv("http://spark-public.s3.amazonaws.com/compfinance/R%20code/lab9returns.csv",
stringsAsFactors=F)
colnames(lab9.df)
# Data for the lab are in the Excel file econ424lab7returns.csv, which contains monthly continuously
# compounded returns on Boeing, Nordstrom, Starbucks and Microsoft stocks over
# the period March, 1995 through January, 2000.
options(digits=4, width=70)
library("zoo")
# load the data into a zoo object using the zoo function read.csv
source(file="http://spark-public.s3.amazonaws.com/compfinance/R%20code/portfolio.r")
lab9.df = read.csv("http://spark-public.s3.amazonaws.com/compfinance/R%20code/lab9returns.csv",
stringsAsFactors=F)
colnames(lab9.df)
#
# 2. Create zoo object from data and dates in lab7.df
#
lab9.z = zoo(x=lab9.df[, -1],
order.by=as.yearmon(lab9.df[, 1], format="%b-%y"))
start(lab9.z)
end(lab9.z)
colnames(lab9.z)
#
# 3. Create timePlots of data
#
# create custom panel function to draw horizontal line at zero in each panel
# of plot
my.panel <- function(...) {
lines(...)
abline(h=0)
}
plot(lab9.z, lwd=2, panel=my.panel, col="blue")
# all on the same graph
plot(lab9.z, plot.type = "single", main="lab9 returns",
col=1:4, lwd=2)
abline(h=0)
legend(x="bottomleft", legend=colnames(lab7.z), col=1:4, lwd=2)
legend(x="bottomleft", legend=colnames(lab9.z), col=1:4, lwd=2)
#
# 4. Compute pairwise scatterplots
#
pairs(coredata(lab9.z), col="blue", pch=16)
#
# 5. Compute estimates of CER model parameters
#
muhat.vals = apply(lab9.z, 2, mean)
muhat.vals
# 5. Compute estimates of CER model parameters
#
muhat.vals = apply(lab9.z, 2, mean)
muhat.vals
sigma2hat.vals = apply(lab9.z, 2, var)
sigma2hat.vals
sigmahat.vals = apply(lab9.z, 2, sd)
sigmahat.vals
cov.mat = var(lab9.z)
cov.mat
cor.mat = cor(lab9.z)
cor.mat
#
# 6. Export means and covariance matrix to .csv file for
#    import to Excel. Be sure to change the directories to the appropriate ones on your
#    computer
#
write.csv(muhat.vals, file="C:\\Users\\ezivot\\Documents\\classes\\econ424\\fall2010\\muhatVals.csv")
write.csv(cov.mat, file="C:\\Users\\ezivot\\Documents\\classes\\econ424\\fall2010\\covMat.csv")
#
#
write.csv(muhat.vals, file="C:\Users\Dave\Documents\compFinance\muhatVals.csv")
write.csv(cov.mat, file="C:\Users\Dave\Documents\compFinance\covMat.csv")
write.csv(muhat.vals, file="C:\\Users\\Dave\\Documents\\compFinance\\muhatVals.csv")
write.csv(cov.mat, file="C:\\Users\\Dave\\Documents\\compFinance\\covMat.csv")
#
# portfolio theory calculations using functions in portfolio.r
#
# compute global minimum variance portfolio with short sales
gmin.port = globalMin.portfolio(muhat.vals, cov.mat)
gmin.port
plot(gmin.port, col="blue")
# compute efficient portfolio with target return equal to highest average return
mu.target = max(muhat.vals)
e1.port = efficient.portfolio(muhat.vals, cov.mat, mu.target)
e1.port
plot(e1.port, col="blue")
# compute covariance b/w min var portfolio and efficient port
t(gmin.port$weights)%*%cov.mat%*%e1.port$weights
# compute efficient frontier of risk assets and plot
e.frontier = efficient.frontier(muhat.vals, cov.mat, alpha.min=-1, alpha.max=1)
summary(e.frontier)
plot(e.frontier, plot.assets=T, col="blue", pch=16, cex=2)
# compute tangency portfolio with rf = 0.005
tan.port = tangency.portfolio(muhat.vals, cov.mat, risk.free=0.005)
summary(tan.port)
plot(tan.port, col="blue")
# efficient portfolio of T-bills + tangency that has the same SD as sbux
names(tan.port)
x.tan = sigmahat.vals["Starbucks"]/tan.port$sd
x.tan
mu.pe = 0.005 + x.tan*(tan.port$er - 0.005)
mu.pe
mu.pe
mu.pe
mu.pe
mu.pe
# compute global minimum variance portfolio with short sales
gmin.port = globalMin.portfolio(muhat.vals, cov.mat)
gmin.port
plot(gmin.port, col="blue")
# compute efficient portfolio with target return equal to highest average return
mu.target = max(muhat.vals)
e1.port = efficient.portfolio(muhat.vals, cov.mat, mu.target)
e1.port
plot(e1.port, col="blue")
# compute covariance b/w min var portfolio and efficient port
t(gmin.port$weights)%*%cov.mat%*%e1.port$weights
e1.port = efficient.portfolio(muhat.vals, cov.mat, mu.target)
e1.port
plot(e1.port, col="blue")
# compute covariance b/w min var portfolio and efficient port
t(gmin.port$weights)%*%cov.mat%*%e1.port$weights
# compute efficient frontier of risk assets and plot
e.frontier = efficient.frontier(muhat.vals, cov.mat, alpha.min=-1, alpha.max=1)
summary(e.frontier)
plot(e.frontier, plot.assets=T, col="blue", pch=16, cex=2)
# compute tangency portfolio with rf = 0.005
tan.port = tangency.portfolio(muhat.vals, cov.mat, risk.free=0.005)
summary(tan.port)
plot(tan.port, col="blue")
# efficient portfolio of T-bills + tangency that has the same SD as sbux
names(tan.port)
x.tan = sigmahat.vals["Starbucks"]/tan.port$sd
x.tan
mu.pe = 0.005 + x.tan*(tan.port$er - 0.005)
mu.pe
qnorm(.05,0.0185,0.059)
x <- rnorm(100, mean=5, sd=2)
x
x <- ceiling(rnomr(23, mean 14, sd=2))
x <- ceiling(rnomr(23, mean =14, sd=2))
x <- ceiling(rnorm(23, mean =14, sd=2))
x
\help (p)
help (p)
help(p)
??p
??tinterval
library("lattice")
??tinterval
fileUrlQ3 <-"https://dl.dropbox.com/u/7710864/data/csv_hid/ss06hid.csv"
houses<-read.csv(fileUrlQ3)
hVAL <- houses[houses$VAL == 24, c("VAL")]
table(is.na(hVAL))
agricultureLogical <- houses[houses$ACR == 3 & houses$AGS == 6]
agricultureLogical <-c(houses$ACR == 3 & houses$AGS == 6)
which(agricultureLogical)
fix(agricultureLogical)
indexes = which(agricultureLogical)
subsetHouses = houses[indexes,]
table(is.na(subsetHouses))
View(subsetHouses)
table(is.na(subsetHouses$MRGX))
splitNames = strsplit(names(houses), "wgtp")
splitNames[[123]]
quantile(houses$YBL)
quantile(na.rm(houses$YBL)
quantile(na.rm(houses$YBL))
quantile(na.rm(houses$YBL))
quantile(houses$YBL, na.rm = TRUE)
quantile(houses$YBL, na.rm = FALSE)
quantile(houses$YBL, na.rm)
quantile(houses$YBL, na.rm = TRUE)
error = qnorm(alpha)*(s/sqrt(n))
alpha = 0.05
n = 100
muhat = 12
s = 4
error = qnorm(alpha)*(s/sqrt(n))
critValue = muhat + error
x <- c(12.0, 10.5, 13.5, 12.5, 9.5, 6.3, 7.2)
mean(x)
median(x)
stdev(x)
stats*x)
stats(x)
sd(x)
x-(sd/sqrt(6))
x-(sd(x)/sqrt(6))
mean(x)-(sd(x)/sqrt(6))
mean(x)-qnorm(.975)(sd(x)/sqrt(6))
mean(x)-qnorm(.975)*(sd(x)/sqrt(6))
mean(x)+qnorm(.975)*(sd(x)/sqrt(6))
qnorm(.975)
mean(x) + 1.96*(sd(x)/sqrt(6))
mean(x) - 1.96*(sd(x)/sqrt(6))
fix(x)
confint(x)
?uniform()
punif(.75)
punif(0.5)
dunif(0.5)
dunif(0.75)
plot(xval, yval, type = "l", axes = TRUE, frame = FALSE, lwd = 3, xlab = "", ylab = "")
qnorm(.95)
xval <- seq(-3.2, 3.2, length = 1000)
yval<- dnorm(xval)
plot(xval, yval, type = "l", axes = TRUE, frame = FALSE, lwd = 3, xlab = "", ylab = "")
x <- seq(qnorm(.95), 3.2, length = 100)
polygon(c(x, rev(x)),c(dnorm(x), rep(0, length(x))), col = "salmon")
text(mean(x), mean(dnorm(x))+.02, "5%", cex = 2)
xval <-seq(0, 1, length = 1000)
yval <- dunif(xval)
plot(xval, yval, type="1", axes = TRUE, frame = F, lwd = 3, xlab = "", ylav = "")
xval <- seq(-3.2, 3.2, length = 1000)
yval<- dnorm(xval)
plot(xval, yval, type = "l", axes = TRUE, frame = FALSE, lwd = 3, xlab = "", ylab = "")
plot(xval, yval, type="1", axes = TRUE, frame = FALSE, lwd = 3, xlab = "", ylab = "")
xval <-seq(0, 1, length = 1000)
yval <- dunif(xval)
plot(xval, yval, type="1", axes = TRUE, frame = FALSE, lwd = 3, xlab = "", ylab = "")
plot(xval, yval, type = "l", axes = TRUE, frame = FALSE, lwd = 3, xlab = "", ylab = "")
polygon(c(x, rev(x)),c(dnorm(x), rep(0, length(x))), col = "salmon")
x <- seq(qnorm(.95), 3.2, length = 100)
polygon(c(x, rev(x)),c(dnorm(x), rep(0, length(x))), col = "salmon")
text(mean(x), mean(dnorm(x))+.02, "5%", cex = 2)
text(qnorm(.95), .01, "1.645", cex = 2)
xval <-seq(0, 1, length = 1000)
yval <- dunif(xval)
plot(xval, yval, type="1", axes = TRUE, frame = FALSE, lwd = 3, xlab = "", ylab = "")
plot(xval, yval, type = "l", axes = TRUE, frame = FALSE, lwd = 3, xlab = "", ylab = "")
plot(xval, yval, type = "l", axes = TRUE, frame = TRUE, lwd = 3, xlab = "", ylab = "")
xval <- seq(-3.2, 3.2, length = 1000)
yval<- dnorm(xval)
plot(xval, yval, type = "l", axes = TRUE, frame = FALSE, lwd = 3, xlab = "", ylab = "")
xval <- seq(-3.2, 3.2, length = 1000)
yval<- dnorm(xval)
plot(xval, yval, type = "l", axes = TRUE, frame = FALSE, lwd = 3, xlab = "", ylab = "")
x <- seq(qnorm(.95), 3.2, length = 100)
polygon(c(x, rev(x)),c(dnorm(x), rep(0, length(x))), col = "salmon")
text(mean(x), mean(dnorm(x))+.02, "5%", cex = 2)
text(qnorm(.95), .01, "1.645", cex = 2)
brain = c(965, 1029, 1030, 1285, 1049, 1077, 1037, 1068, 1176, 1105)
IQ = c(90, 85, 86, 102, 103, 97, 124, 125, 102, 114)
df = data.frame (brain, IQ)
df
plot(df$brain,df$IQ)
plot(df$brain,df$IQ, xlab= "Brain Size in cubic cm", ylab = "IQ")
abline(lm(IQ ~ brain))
plot(df$brain,df$IQ, xlab= "Brain Size in cubic cm", ylab = "IQ", type = "n")
plot(df$brain,df$IQ, xlab= "Brain Size in cubic cm", ylab = "IQ")
abline(lm(IQ ~ brain))
points( mean(brain), mean(IQ))
points( mean(brain), mean(IQ), pch = 21)
points( mean(brain), mean(IQ), pch = 21)
df = data.frame (brain, IQ)
df
plot(df$brain,df$IQ, xlab= "Brain Size in cubic cm", ylab = "IQ")
abline(lm(IQ ~ brain))
points( mean(brain), mean(IQ), pch = 21)
points( mean(brain), mean(IQ), pch = 21)
points( mean(brain), mean(IQ), pch = 19)
abline(mean(brain))
abline(mean(brain),0)
abline(mean(brain),0)
df
plot(df$brain,df$IQ, xlab= "Brain Size in cubic cm", ylab = "IQ")
abline(lm(IQ ~ brain))
points( mean(brain), mean(IQ), pch = 19)
abline(mean(brain),0)
abline(mean(brain),0)
abline(mean(brain),0)
abline(mean(brain),b = 0)
abline(mean(brain),b = 0)
abline(lm(IQ ~ brain))
points( mean(brain), mean(IQ), pch = 19)
abline(mean(brain),b = 0)
abline(mean(IQ),b = 0)
abline(mean(IQ),b = 0, lty = 3)
abline(mean(IQ),b = 0, lty = 3)
abline(lm(IQ ~ brain))
points( mean(brain), mean(IQ), pch = 19)
abline(mean(IQ),b = 0, lty = 3)
abline(mean(IQ),b = 0, lty = 3)
abline(mean(IQ),b = 0, 1ty = 3)
abline(mean(IQ),b = 0, lty=3)
abline(mean(IQ),b = 0, lty=2)
abline(mean(IQ),b = 0, lty=5)
abline(mean(IQ),b = 0, \dots)
df
plot(df$brain,df$IQ, xlab= "Brain Size in cubic cm", ylab = "IQ")
abline(lm(IQ ~ brain))
points( mean(brain), mean(IQ), pch = 19)
abline(mean(IQ),b = 0, lty=2)
abline(mean(IQ),b = 0, lty=2)
abline(v=mean(brain), lty=2)
sd(c(5,8,12))
which.min(c(4,1,6))
xval <- seq(-3.2, 3.2, length = 1000)
yval<- dchisq(xval, 3)
plot(xval, yval, type = "l", axes = TRUE, frame = FALSE, lwd = 3, xlab = "", ylab = "")
xval <- seq(0, 14, length = 1000)
yval<- dchisq(xval, 3)
plot(xval, yval, type = "l", axes = TRUE, frame = FALSE, lwd = 3, xlab = "", ylab = "")
library(ggplot2)
install.packages(c("akima", "bitops", "boot", "car", "cluster", "digest", "fAssets", "fBasics", "fCopulae", "foreign", "KernSmooth", "lattice", "locfit", "MASS", "mgcv", "mnormt", "mvtnorm", "nlme", "nnet", "PerformanceAnalytics", "psych", "quadprog", "RCurl", "Rglpk", "robustbase", "rpart", "slam", "stabledist", "survival", "timeDate", "timeSeries", "TSA", "tseries", "xts", "zoo"))
install.packages("ggplot2")
library("ggplot2")
library(ggplot2)
eq <- function(x) {x*x}
tmp <- data.frame(x=1:50, y=eq(1:50))
# Make plot object
p <- qplot(x, y, data=tmp, xlab="X-axis", ylab="Y-axis")
c <- stat_function(fun=eq)
print(p + c)
p1 <- qplot(xval, yval, type = "l", axes = TRUE, frame = FALSE, lwd = 3, xlab = "", ylab = "")
pritn(p1)
print(p1)
xval <- seq(0, 14, length = 100000)
yval<- dchisq(xval, 3)
yval2<-dchisq(xval, 5)
yval3 <- dchisq(xval, 10)
p1 <- qplot(xval, yval, type = "l", axes = TRUE, frame = FALSE, lwd = 3, xlab = "", ylab = "")
print(p1)
p2 <- qplot(xval, yval2, type = "l", axes = TRUE, frame = FALSE, lwd = 1, xlab = "", ylab = "")
print(p1 + p2)
p1 <- plot(xval, yval, type = "l", axes = TRUE, frame = FALSE, lwd = 3, xlab = "", ylab = "")
print(p1 + p2)
plot(x, yval, type = "l", axes = TRUE, frame = FALSE, lwd = 3, xlab = "", ylab = "")
x <- seq(0, 14, length = 1000)
yval<- dchisq(xval, 3)
yval<- dchisq(x, 3)
plot(x, yval, type = "l", axes = TRUE, frame = FALSE, lwd = 3, xlab = "", ylab = "")
curve(dchisq(df =5))
curve(dchisq(x,df =5))
plot(x, yval, type = "l", axes = TRUE, frame = FALSE, lwd = 3, xlab = "", ylab = "")
curve(dchisq(x,df =5))
curve(dchisq(x,df =5), add= T)
plot(x, yval, type = "l", axes = TRUE, frame = FALSE, lwd = 3, xlab = "", ylab = "")
curve(dchisq(x,df =5), add= T)
plot(x, yval, type = "l", axes = TRUE, frame = FALSE, lwd = 1, xlab = "", ylab = "")
curve(dchisq(x,df =5), add= T)
plot(x, yval, type = "l", axes = TRUE, frame = FALSE, lwd = 1, xlab = "", ylab = "")
curve(dchisq(x,df =5), add= T col = "blue")
curve(dchisq(x,df =5), add= T, col = "blue")
curve(dchisq(x,df =10), add=T, col = "green")
curve(dchisq(x,df =8), add=T, col = "green")
x <- seq(0, 15, length = 1000)
yval<- dchisq(x, 3)
plot(x, yval, type = "l", axes = TRUE, frame = FALSE, lwd = 1, xlab = "", ylab = "")
curve(dchisq(x,df =5), add= T, col = "blue")
curve(dchisq(x,df =8), add=T, col = "green")
curve(dchisq(x,df =10), add=T, col = "green")
x <- seq(0, 15, length = 1000)
yval<- dchisq(x, 3)
x <- seq(0, 15, length = 1000)
yval<- dchisq(x, 3)
plot(x, yval, type = "l", axes = TRUE, frame = FALSE, lwd = 1, xlab = "", ylab = "")
curve(dchisq(x,df =5), add= T, col = "blue")
curve(dchisq(x,df =10), add=T, col = "green")
text(1, mean(dchisq(x,3))+.02, "5%", cex = 2)
text(2, mean(dchisq(x,3))+.02, "5%", cex = 2)
text(2, mdchisq(x,3)+.02, "5%", cex = 2)
text(2, mdchisq(x,3)+.02, "5%", cex = 2)
text(2, dchisq(x,3)+.02, "5%", cex = 2)
x <- seq(0, 15, length = 1000)
yval<- dchisq(x, 3)
plot(x, yval, type = "l", axes = TRUE, frame = FALSE, lwd = 1, xlab = "", ylab = "")
curve(dchisq(x,df =5), add= T, col = "blue")
curve(dchisq(x,df =10), add=T, col = "green")
x <- seq(0, 15, length = 1000)
yval<- dchisq(x, 3)
plot(x, yval, type = "l", axes = TRUE, frame = FALSE, lwd = 1, xlab = "", ylab = "")
curve(dchisq(x,df =5), add= T, col = "blue")
curve(dchisq(x,df =10), add=T, col = "violet")
x <- seq(0, 15, length = 1000)
yval<- dchisq(x, 3)
plot(x, yval, type = "l", axes = TRUE, frame = FALSE, lwd = 1, xlab = "", ylab = "")
curve(dchisq(x,df =5), add= T, col = "blue")
curve(dchisq(x,df =10), add=T, col = "red")
x <- seq(0, 20, length = 1000)
yval<- dchisq(x, 3)
plot(x, yval, type = "l", axes = TRUE, frame = FALSE, lwd = 1, xlab = "", ylab = "")
curve(dchisq(x,df =5), add= T, col = "blue")
curve(dchisq(x,df =10), add=T, col = "red")
1 -(.36^2 + .64^2)
-(.36*log(.36,2) + .64*log(.64,2))
-(.36*log(.36) + .64*log(.64))
x <- seq(0, 10, length = 1000)
yval<- df(x, 3)
plot(x, yval, type = "l", axes = TRUE, frame = FALSE, lwd = 1, xlab = "", ylab = "")
x <- seq(0, 10, length = 1000)
yval<- df(x, 3)
x <- seq(0, 10, length = 1000)
yval<- df(x, 3, 3)
plot(x, yval, type = "l", axes = TRUE, frame = FALSE, lwd = 1, xlab = "", ylab = "")
yval<- df(x, 3, 4)
plot(x, yval, type = "l", axes = TRUE, frame = FALSE, lwd = 1, xlab = "", ylab = "")
x <- seq(0, 10, length = 1000)
yval<- df(x, 3, 10)
plot(x, yval, type = "l", axes = TRUE, frame = FALSE, lwd = 1, xlab = "", ylab = "")
x <- seq(0, 10, length = 1000)
yval<- df(x, 10, 10)
plot(x, yval, type = "l", axes = TRUE, frame = FALSE, lwd = 1, xlab = "", ylab = "")
x = c(0,1,1)
y = c(2,2,8)
df = [x,y]
df = cbind(x,y)
lm(df$y~df$x)
lm(y~x)
linearModel = lm(y~x)
summary(linearModel)
linearModel
mean(df$y)
mean(y)
R.version.string
find.package('devtools')
find.package("devtools")
find.package("devtools")
install.packages("devtools")
library(devtools)
find_rtools()
?write.table
setwd("~/R/getdata/getDataProject")
setwd("~/R/getdata/getDataProject")
=======
# Reading the unzipped data.
xTest <- read.table("./UCI HAR Dataset//test/X_test.txt", sep="")
yTest <- read.table("./UCI HAR Dataset/test/y_test.txt", sep="")
subTest <- read.table("./UCI HAR Dataset/test/subject_test.txt", sep="")
xTrain <- read.table("./UCI HAR Dataset/train/X_train.txt", sep="")
yTrain <- read.table("./UCI HAR Dataset/train/y_train.txt", sep="")
subTrain <- read.table("./UCI HAR Dataset/train/subject_train.txt", sep="")
# Putting the data together, first we column bind the xtest, ytest into test and xtrain, ytrain into train data.
# Then we will row bind test and train.
test<- cbind(xTest, yTest,subTest)
train <- cbind(xTrain, yTrain, subTrain)
rawdata <- rbind(train, test)
# subsetting rawdata for features with "mean" or "std" in their name, note I choose excluded the features with "meanFreq"
# in the name as it was a weighted average where I am unsure of how it was wieghted.
ms_cols <-c(1:6,41:46,81:86, 121:126, 161:166, 201:202, 214:215, 227:228, 240:241, 253:254, 266:271,
345:350,  424:429,  503:504, 516:517, 529:530, 542:543, 555:561, 562, 563 )
data <-rawdata[,ms_cols]
summary(data)
head(data)
# Now we are going to give descriptive names to the coded activity labels from the original y data sets.
data[data[,74] == 1,74]  <- "walking"
data[data[,74] == 2,74]  <- "walkindatagUp"
data[data[,74] == 3,74]  <- "walkingDown"
data[data[,74] == 4,74]  <- "sitting"
data[data[,74] == 5,74]  <- "standing"
data[data[,74] == 6,74]  <- "laying"
# The following code should rename the variable names from V1, V2 to something more descriptive.
# Using a powerful text editor (notepade++)I found all the feature names in features.txt including the the word "mean" and "std",
# and excluded meanFreq.  I saved the list of features as a txt file "vnames.txt"  I read it in as a table and grabbed all the names
# from the 4th column which is the name given for each column by the original researchers.  If you investigate vnames.txt you will
# see that I did some minor editting.  Each name that ends with mean included an "()" which I have edited out.
vnames <- read.table("vnames.txt", header = F)
head(vnames)
tail(vnames)
names(data) <- vnames[,4]
#("tBodyAcc_mean_X", "tBodyAcc_mean_Y", "tBodyAcc_mean_Z", "tGravityAcc-mean()-X", "tGravityAcc-mean-Y",
#              "tGravityAcc-mean-Z", "tBodyAccJerk-mean()-X", "tBodyAccJerk-mean()-Y", "tBodyAccJerk-mean()-Z")
summary(data)
## We use melt along with dcast to form tidy data.  We select "SubjectID" and "Activity" is ID variables and use melt to create
## dataMelt.  Using dcast on dataMelt we find the mean of all variables broken down by SubjectId and Activity.  We save the result as
## tidyData
library(reshape2)
dataMelt <- melt(data, id = c("SubjectID", "Activity"))
head(dataMelt)
tidyData <- dcast(dataMelt, SubjectID + Activity ~ variable, mean)
write.table("tidyData.txt", row.name = F)
write.table(tidyData, file = "tidyData.txt", row.name = F)
